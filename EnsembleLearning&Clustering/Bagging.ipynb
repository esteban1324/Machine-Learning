{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will go through the bagging technique of ensemble learning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Generate a random dataset with 20 samples.  Each should have two input labels and 1 output label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67795555 0.5129588  1.        ]\n",
      " [0.62370571 0.47714247 1.        ]\n",
      " [0.46025981 0.95086487 0.        ]\n",
      " [0.9845756  0.85442255 1.        ]\n",
      " [0.59109035 0.20319637 0.        ]\n",
      " [0.26236016 0.06641525 0.        ]\n",
      " [0.64693501 0.71873295 1.        ]\n",
      " [0.35104926 0.95254348 0.        ]\n",
      " [0.59547743 0.99450621 0.        ]\n",
      " [0.54367354 0.07171263 0.        ]\n",
      " [0.14068668 0.20727832 0.        ]\n",
      " [0.50552741 0.53539293 1.        ]\n",
      " [0.53145508 0.23291118 0.        ]\n",
      " [0.60550138 0.70289106 0.        ]\n",
      " [0.06662988 0.2366768  1.        ]\n",
      " [0.15895731 0.97330243 0.        ]\n",
      " [0.71025347 0.08285516 1.        ]\n",
      " [0.54836989 0.1424483  0.        ]\n",
      " [0.10721273 0.61757862 0.        ]\n",
      " [0.91187275 0.90530837 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(120)\n",
    "\n",
    "# generate random data with last column as target\n",
    "data = np.random.rand(20,2)\n",
    "target = np.random.randint(0,2,20)\n",
    "\n",
    "data = np.concatenate((data, target.reshape(-1,1)), axis=1)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Generate 10 training datasets with a size of 20, by sampling with repetition and produce output as a 10 x 20 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.15895731 0.97330243 0.        ]\n",
      "  [0.59547743 0.99450621 1.        ]\n",
      "  [0.10721273 0.61757862 1.        ]\n",
      "  [0.81672161 0.45674108 0.        ]\n",
      "  [0.0643363  0.46147051 1.        ]\n",
      "  [0.10621653 0.33940194 1.        ]\n",
      "  [0.54367354 0.07171263 0.        ]\n",
      "  [0.31941841 0.69046799 0.        ]\n",
      "  [0.54836989 0.1424483  0.        ]\n",
      "  [0.54836989 0.1424483  0.        ]\n",
      "  [0.54836989 0.1424483  0.        ]\n",
      "  [0.06662988 0.2366768  1.        ]\n",
      "  [0.18047251 0.05859209 1.        ]\n",
      "  [0.26232429 0.26463542 0.        ]\n",
      "  [0.54367354 0.07171263 0.        ]\n",
      "  [0.53145508 0.23291118 1.        ]\n",
      "  [0.60550138 0.70289106 1.        ]\n",
      "  [0.15895731 0.97330243 0.        ]\n",
      "  [0.26232429 0.26463542 0.        ]\n",
      "  [0.29197057 0.85226147 0.        ]]\n",
      "\n",
      " [[0.65102413 0.29737596 0.        ]\n",
      "  [0.89960275 0.67574196 0.        ]\n",
      "  [0.42978814 0.40965052 0.        ]\n",
      "  [0.76086314 0.63246615 1.        ]\n",
      "  [0.38643837 0.51336481 0.        ]\n",
      "  [0.33365635 0.00433633 1.        ]\n",
      "  [0.18771727 0.70312797 0.        ]\n",
      "  [0.65102413 0.29737596 0.        ]\n",
      "  [0.17330667 0.7971762  0.        ]\n",
      "  [0.18771727 0.70312797 0.        ]\n",
      "  [0.42978814 0.40965052 0.        ]\n",
      "  [0.33365635 0.00433633 1.        ]\n",
      "  [0.07926071 0.80050729 1.        ]\n",
      "  [0.13464396 0.112861   0.        ]\n",
      "  [0.89960275 0.67574196 0.        ]\n",
      "  [0.24646765 0.3690341  1.        ]\n",
      "  [0.36441432 0.37691837 0.        ]\n",
      "  [0.13464396 0.112861   0.        ]\n",
      "  [0.17330667 0.7971762  0.        ]\n",
      "  [0.42978814 0.40965052 0.        ]]\n",
      "\n",
      " [[0.03837557 0.64269193 0.        ]\n",
      "  [0.41300061 0.38410558 1.        ]\n",
      "  [0.83303693 0.24751215 1.        ]\n",
      "  [0.14852901 0.71277819 1.        ]\n",
      "  [0.52795101 0.90479177 1.        ]\n",
      "  [0.73933801 0.56418657 0.        ]\n",
      "  [0.96162316 0.62778448 1.        ]\n",
      "  [0.79746047 0.05675777 1.        ]\n",
      "  [0.14852901 0.71277819 1.        ]\n",
      "  [0.96162316 0.62778448 1.        ]\n",
      "  [0.03837557 0.64269193 0.        ]\n",
      "  [0.52795101 0.90479177 1.        ]\n",
      "  [0.41300061 0.38410558 1.        ]\n",
      "  [0.52795101 0.90479177 1.        ]\n",
      "  [0.34381254 0.6241844  1.        ]\n",
      "  [0.0182105  0.83624423 0.        ]\n",
      "  [0.45145713 0.54766325 0.        ]\n",
      "  [0.34381254 0.6241844  1.        ]\n",
      "  [0.41300061 0.38410558 1.        ]\n",
      "  [0.21784594 0.69202436 0.        ]]\n",
      "\n",
      " [[0.76825972 0.0219884  1.        ]\n",
      "  [0.31376446 0.57858399 0.        ]\n",
      "  [0.31376446 0.57858399 0.        ]\n",
      "  [0.35994841 0.51998817 0.        ]\n",
      "  [0.63715542 0.95532739 0.        ]\n",
      "  [0.35994841 0.51998817 0.        ]\n",
      "  [0.33109166 0.72669822 0.        ]\n",
      "  [0.31376446 0.57858399 0.        ]\n",
      "  [0.31376446 0.57858399 0.        ]\n",
      "  [0.33109166 0.72669822 0.        ]\n",
      "  [0.33109166 0.72669822 0.        ]\n",
      "  [0.77803159 0.27968897 0.        ]\n",
      "  [0.76825972 0.0219884  1.        ]\n",
      "  [0.36198599 0.1238585  0.        ]\n",
      "  [0.87138694 0.76658965 1.        ]\n",
      "  [0.76825972 0.0219884  1.        ]\n",
      "  [0.47972609 0.51310457 0.        ]\n",
      "  [0.78433867 0.61682049 1.        ]\n",
      "  [0.63715542 0.95532739 0.        ]\n",
      "  [0.25055504 0.37838068 0.        ]]\n",
      "\n",
      " [[0.79349492 0.60581306 0.        ]\n",
      "  [0.92962731 0.77695553 1.        ]\n",
      "  [0.65965872 0.9729672  1.        ]\n",
      "  [0.46570646 0.13684729 0.        ]\n",
      "  [0.73302489 0.15111269 1.        ]\n",
      "  [0.92962731 0.77695553 1.        ]\n",
      "  [0.87394703 0.47424217 0.        ]\n",
      "  [0.79349492 0.60581306 0.        ]\n",
      "  [0.59483073 0.70321243 1.        ]\n",
      "  [0.45145041 0.53312814 0.        ]\n",
      "  [0.88946523 0.47440266 0.        ]\n",
      "  [0.87394703 0.47424217 0.        ]\n",
      "  [0.45145041 0.53312814 0.        ]\n",
      "  [0.59483073 0.70321243 1.        ]\n",
      "  [0.79349492 0.60581306 0.        ]\n",
      "  [0.46570646 0.13684729 0.        ]\n",
      "  [0.65965872 0.9729672  1.        ]\n",
      "  [0.65965872 0.9729672  1.        ]\n",
      "  [0.46570646 0.13684729 0.        ]\n",
      "  [0.65965872 0.9729672  1.        ]]\n",
      "\n",
      " [[0.3486561  0.28503147 1.        ]\n",
      "  [0.00317831 0.89857498 0.        ]\n",
      "  [0.95335203 0.70880784 0.        ]\n",
      "  [0.5944986  0.01805124 1.        ]\n",
      "  [0.06813901 0.14814484 1.        ]\n",
      "  [0.5944986  0.01805124 1.        ]\n",
      "  [0.5944986  0.01805124 1.        ]\n",
      "  [0.67171624 0.99143375 0.        ]\n",
      "  [0.60678797 0.8734406  1.        ]\n",
      "  [0.06813901 0.14814484 1.        ]\n",
      "  [0.81819489 0.651927   0.        ]\n",
      "  [0.34668059 0.65812032 1.        ]\n",
      "  [0.3486561  0.28503147 1.        ]\n",
      "  [0.3486561  0.28503147 1.        ]\n",
      "  [0.3486561  0.28503147 1.        ]\n",
      "  [0.81819489 0.651927   0.        ]\n",
      "  [0.60678797 0.8734406  1.        ]\n",
      "  [0.3542132  0.30442074 1.        ]\n",
      "  [0.29095129 0.45679629 1.        ]\n",
      "  [0.28681606 0.46507905 0.        ]]\n",
      "\n",
      " [[0.76651186 0.55548155 1.        ]\n",
      "  [0.11264081 0.60750058 1.        ]\n",
      "  [0.72926481 0.68962315 1.        ]\n",
      "  [0.76487933 0.50371045 0.        ]\n",
      "  [0.85834441 0.4283596  0.        ]\n",
      "  [0.27950782 0.66802266 0.        ]\n",
      "  [0.75469483 0.41276522 1.        ]\n",
      "  [0.9297857  0.35518502 1.        ]\n",
      "  [0.90442559 0.41230294 1.        ]\n",
      "  [0.76487933 0.50371045 0.        ]\n",
      "  [0.26617965 0.57207601 0.        ]\n",
      "  [0.96681914 0.89419168 1.        ]\n",
      "  [0.9297857  0.35518502 1.        ]\n",
      "  [0.26617965 0.57207601 0.        ]\n",
      "  [0.1256439  0.31664464 1.        ]\n",
      "  [0.1256439  0.31664464 1.        ]\n",
      "  [0.76651186 0.55548155 1.        ]\n",
      "  [0.18296905 0.19948328 1.        ]\n",
      "  [0.1256439  0.31664464 1.        ]\n",
      "  [0.1256439  0.31664464 1.        ]]\n",
      "\n",
      " [[0.652732   0.46077707 0.        ]\n",
      "  [0.98037089 0.91262587 0.        ]\n",
      "  [0.21306808 0.51807592 0.        ]\n",
      "  [0.51900372 0.15159213 1.        ]\n",
      "  [0.36756522 0.21303883 1.        ]\n",
      "  [0.32303945 0.08541043 0.        ]\n",
      "  [0.98037089 0.91262587 0.        ]\n",
      "  [0.652732   0.46077707 0.        ]\n",
      "  [0.97644114 0.10936992 0.        ]\n",
      "  [0.96302295 0.78083764 0.        ]\n",
      "  [0.96302295 0.78083764 0.        ]\n",
      "  [0.10056392 0.26533094 1.        ]\n",
      "  [0.29101191 0.23556637 0.        ]\n",
      "  [0.29101191 0.23556637 0.        ]\n",
      "  [0.84005899 0.55076503 0.        ]\n",
      "  [0.85796119 0.52614663 1.        ]\n",
      "  [0.10056392 0.26533094 1.        ]\n",
      "  [0.98037089 0.91262587 0.        ]\n",
      "  [0.16532317 0.38808695 0.        ]\n",
      "  [0.96302295 0.78083764 0.        ]]\n",
      "\n",
      " [[0.7154927  0.50732203 0.        ]\n",
      "  [0.92562806 0.50924331 0.        ]\n",
      "  [0.96085526 0.00505381 0.        ]\n",
      "  [0.689414   0.6109849  0.        ]\n",
      "  [0.48672176 0.13001657 0.        ]\n",
      "  [0.79430386 0.28251776 0.        ]\n",
      "  [0.56641726 0.81698137 0.        ]\n",
      "  [0.46046341 0.25097042 0.        ]\n",
      "  [0.81437915 0.70171031 0.        ]\n",
      "  [0.03985732 0.81430562 1.        ]\n",
      "  [0.96085526 0.00505381 0.        ]\n",
      "  [0.72598751 0.00596921 0.        ]\n",
      "  [0.20723502 0.23996936 0.        ]\n",
      "  [0.81437915 0.70171031 0.        ]\n",
      "  [0.72598751 0.00596921 0.        ]\n",
      "  [0.03985732 0.81430562 1.        ]\n",
      "  [0.72598751 0.00596921 0.        ]\n",
      "  [0.56641726 0.81698137 0.        ]\n",
      "  [0.46046341 0.25097042 0.        ]\n",
      "  [0.79840755 0.41455667 0.        ]]\n",
      "\n",
      " [[0.80993233 0.82449189 1.        ]\n",
      "  [0.80993233 0.82449189 1.        ]\n",
      "  [0.38964358 0.68820832 1.        ]\n",
      "  [0.62066851 0.40446574 1.        ]\n",
      "  [0.76052366 0.43554142 1.        ]\n",
      "  [0.73396847 0.03054941 1.        ]\n",
      "  [0.47802851 0.6928105  0.        ]\n",
      "  [0.80993233 0.82449189 1.        ]\n",
      "  [0.57226959 0.72934277 1.        ]\n",
      "  [0.96968921 0.08945505 1.        ]\n",
      "  [0.2283721  0.62856517 1.        ]\n",
      "  [0.47802851 0.6928105  0.        ]\n",
      "  [0.57476887 0.61622558 1.        ]\n",
      "  [0.55623943 0.02488346 0.        ]\n",
      "  [0.15464618 0.26426238 0.        ]\n",
      "  [0.11878155 0.3812348  0.        ]\n",
      "  [0.27187609 0.5516398  1.        ]\n",
      "  [0.38964358 0.68820832 1.        ]\n",
      "  [0.73396847 0.03054941 1.        ]\n",
      "  [0.55623943 0.02488346 0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(120)\n",
    "\n",
    "training_data_lst = []\n",
    "\n",
    "for _ in range(10):\n",
    "    indices = np.random.choice(20,20, replace=True)\n",
    "    training_data = np.random.rand(20,2)[indices]\n",
    "    training_target = np.random.randint(0,2,20)[indices]\n",
    "    training_data = np.concatenate((training_data, training_target.reshape(-1,1)), axis=1)  \n",
    "    training_data_lst.append(training_data)\n",
    "    \n",
    "# convert into numpy array\n",
    "training_data_lst = np.array(training_data_lst)\n",
    "print(training_data_lst)\n",
    "#\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Train 10 classifiers models on the 10 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.75, 0.5, 0.25, 0.75, 0.5, 1.0, 0.75, 0.75, 0.75]\n"
     ]
    }
   ],
   "source": [
    "# save the log reg models in a list or specifically their accuracy metric\n",
    "log_reg_models = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    # create a new log reg model \n",
    "    log_reg = LogisticRegression(solver='liblinear', C=1.0)\n",
    "    \n",
    "    # access first two cols of np array subarray\n",
    "    sub_np_arr = training_data_lst[i]\n",
    "    X = sub_np_arr[:, :2]\n",
    "    y = sub_np_arr[:, -1]\n",
    "    # train and predict on each dataset from training_data_lst \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # fit the log_reg on the training data and predict with testing\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    \n",
    "    # predict accuracy to get the score then save to array\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    log_reg_models.append(accuracy)\n",
    "    \n",
    "    \n",
    "print(log_reg_models)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Majority Voting to get combine results and produce final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: [0.75], Value: 5\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# perform majority voting using acc scores \n",
    "majority_vote = np.mean(log_reg_models) >= 0.5\n",
    "\n",
    "# make a dictionary with key as the accuracy score and value is the number of times it occurs.\n",
    "\n",
    "mode = dict()\n",
    "\n",
    "for i in log_reg_models:\n",
    "    if i in mode:\n",
    "        mode[i] += 1\n",
    "    else:\n",
    "        mode[i] = 1\n",
    "\n",
    "max_val = max(mode.values())\n",
    "max_key = [key for key, value in mode.items() if max_val == value]\n",
    "\n",
    "print(f\"Key: {max_key}, Value: {max_val}\")\n",
    "print(majority_vote)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
