{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random dataset with 20 samples. Each sample should have two input\n",
    "features and 1 output label (-1 or 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.67795555  0.5129588   1.        ]\n",
      " [ 0.62370571  0.47714247  1.        ]\n",
      " [ 0.46025981  0.95086487 -1.        ]\n",
      " [ 0.9845756   0.85442255  1.        ]\n",
      " [ 0.59109035  0.20319637 -1.        ]\n",
      " [ 0.26236016  0.06641525 -1.        ]\n",
      " [ 0.64693501  0.71873295  1.        ]\n",
      " [ 0.35104926  0.95254348 -1.        ]\n",
      " [ 0.59547743  0.99450621 -1.        ]\n",
      " [ 0.54367354  0.07171263 -1.        ]\n",
      " [ 0.14068668  0.20727832 -1.        ]\n",
      " [ 0.50552741  0.53539293  1.        ]\n",
      " [ 0.53145508  0.23291118 -1.        ]\n",
      " [ 0.60550138  0.70289106 -1.        ]\n",
      " [ 0.06662988  0.2366768   1.        ]\n",
      " [ 0.15895731  0.97330243 -1.        ]\n",
      " [ 0.71025347  0.08285516  1.        ]\n",
      " [ 0.54836989  0.1424483  -1.        ]\n",
      " [ 0.10721273  0.61757862 -1.        ]\n",
      " [ 0.91187275  0.90530837 -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(120)\n",
    "\n",
    "# generate random data with last column as target\n",
    "data = np.random.rand(20,2)\n",
    "target = np.random.choice([-1,1], size=(20,))\n",
    "\n",
    "data_with_y = np.concatenate((data, target.reshape(-1,1)), axis=1)\n",
    "\n",
    "print(data_with_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train a weak learer decision tree that only has a max-depth of 1. Output the feature and threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Threshold: 0.6146035194396973\n"
     ]
    }
   ],
   "source": [
    "# minimal stump\n",
    "clf = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# train it \n",
    "\n",
    "clf.fit(data, target)\n",
    "\n",
    "# then extract the feature and threshold of the it's split\n",
    "feature_index = clf.tree_.feature[0]\n",
    "threshold_index = clf.tree_.threshold[0]\n",
    "\n",
    "print(f\"Feature: {feature_index}, Threshold: {threshold_index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the prediction errors, calculate the coefficient Î±j and updated weights. Out-\n",
    "put the updated weights.  (Follow AdaBoost Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, feature:0, threshold: 0.6146035194396973 , Alpha: 0.8673005276940532\n",
      "Iteration: 1, feature:1, threshold: 0.8798654675483704 , Alpha: 0.5893274981708232\n",
      "Iteration: 2, feature:0, threshold: 0.08692130818963051 , Alpha: 0.6772728314026555\n",
      "Iteration: 3, feature:1, threshold: 0.2347939908504486 , Alpha: 0.5696755598236067\n",
      "Iteration: 4, feature:1, threshold: 0.5764857828617096 , Alpha: 0.6399569787806594\n",
      "Iteration: 5, feature:0, threshold: 0.6146035194396973 , Alpha: 0.600534776526518\n",
      "Iteration: 6, feature:1, threshold: 0.8798654675483704 , Alpha: 0.42334581249324976\n",
      "Iteration: 7, feature:1, threshold: 0.2347939908504486 , Alpha: 0.39969337717781206\n",
      "Iteration: 8, feature:1, threshold: 0.5764857828617096 , Alpha: 0.5093910746028745\n",
      "Iteration: 9, feature:1, threshold: 0.8798654675483704 , Alpha: 0.389762455039527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m is num_itr \n",
    "def adaBoost_train(data, m):\n",
    "    # initialize the weights and set them to uniform weights that sum to 1\n",
    "    n = data.shape[0]\n",
    "    weights = np.ones(n) / n\n",
    "\n",
    "    alphas = []\n",
    "    errors = []\n",
    "    y_preds = np.zeros(n)\n",
    "    \n",
    "    \n",
    "    for _ in range(m):\n",
    "       \n",
    "        # initialize a decision tree with weak stump and train the tree using the data, target and weights  \n",
    "        classifier = DecisionTreeClassifier(max_depth=1)\n",
    "        classifier.fit(data[:, :-1], data[:, -1], sample_weight=weights)\n",
    "        \n",
    "        # predict class labels \n",
    "        y_pred = classifier.predict(data[:, :-1])\n",
    "                \n",
    "        error = np.sum(weights * (y_pred != data[:, -1])) / np.sum(weights)\n",
    "        \n",
    "        errors.append(error)\n",
    "        \n",
    "        # compute the alpha and append to list\n",
    "        alpha = 0.5 * np.log((1 - error)/ float(error) )\n",
    "        alphas.append(alpha)\n",
    "        \n",
    "        y_preds += alpha * y_pred\n",
    "        \n",
    "        # update weights here \n",
    "        weights = weights * np.exp(-alpha * data[:, -1] * y_pred)\n",
    "        \n",
    "        \n",
    "        # normalize the weights so they sum to 1 \n",
    "        weights = weights / np.sum(weights)\n",
    "        \n",
    "        print(f\"Iteration: {_}, feature:{classifier.tree_.feature[0]}, threshold: {classifier.tree_.threshold[0]} , Alpha: {alpha}\")\n",
    "        \n",
    "    # compute final prediction here \n",
    "    final_pred = np.sign(y_preds)\n",
    "    \n",
    "    return final_pred \n",
    "    \n",
    "adaBoost_train(data_with_y, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
